LLM deliberation workflows

## 0) Resumen ejecutivo

Sistema AI-Agent-Lab V3: orquestador de LLMs (locales y API) con arquitectura modular, escalable y resiliente.

**Caracter√≠sticas principales:**
- Provider Gateway unificado para modelos locales (HuggingFace) y APIs (OpenAI/Anthropic)
- Grafo de orquestaci√≥n con LangGraph para routing din√°mico
- Circuit Breaker para resiliencia ante fallos
- Sistema de registries declarativo para configuraci√≥n
- Logging estructurado y m√©tricas detalladas
- Compatible con migraci√≥n progresiva desde V2

**Stack**: Python, FastAPI, LangChain/LangGraph, HuggingFace Transformers

---

## 1) Objetivos de V3

* Migrar a **Provider Gateway pattern** para unificar acceso a LLMs locales y remotos.
* Declarar **registries** de modelos y estrategias para eliminar hardcode.
* Aislar el **orchestrator** de detalles de ejecuci√≥n.
* Mejorar **logging, m√©tricas y manejo de errores**.
* Preparar infraestructura para **OpenAI/Anthropic adapters**.
* Mantener **compatibilidad progresiva** con Direct Mode.

---

## 2) Entrypoints

* `api/server.py` ‚Üí API REST principal (FastAPI)
* `api/endpoints/orchestrator.py` ‚Üí Endpoint `/api/orchestrate`
* `scripts/direct_inference.py` ‚Üí Modo directo para debug

---

## 3) Mapa de carpetas

```
ai-agent-lab/
‚îú‚îÄ api/
‚îÇ  ‚îú‚îÄ server.py                 # Entrypoint servicio FastAPI
‚îÇ  ‚îî‚îÄ endpoints/
‚îÇ     ‚îú‚îÄ inference.py          # Direct Mode endpoint
‚îÇ     ‚îú‚îÄ orchestrator.py       # Orchestrated Mode endpoint
‚îÇ     ‚îú‚îÄ cache.py              # Cache management
‚îÇ     ‚îî‚îÄ system.py             # Health checks, metrics
‚îÇ
‚îú‚îÄ langchain_integration/
‚îÇ  ‚îî‚îÄ langgraph/
‚îÇ     ‚îú‚îÄ routing_agent.py      # Orquestador principal (simplificado)
‚îÇ     ‚îú‚îÄ agent_state.py        # Estado compartido del grafo
‚îÇ     ‚îú‚îÄ orchestration/        # **NUEVO** Sistema modular
‚îÇ     ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ     ‚îÇ  ‚îú‚îÄ graph_builder.py   # Construcci√≥n de grafos
‚îÇ     ‚îÇ  ‚îú‚îÄ graph_configs.py   # Configuraciones declarativas
‚îÇ     ‚îÇ  ‚îî‚îÄ flow_metrics.py    # M√©tricas para frontend
‚îÇ     ‚îî‚îÄ nodes/                # Nodos del grafo
‚îÇ        ‚îú‚îÄ task_analyzer_node.py
‚îÇ        ‚îú‚îÄ resource_monitor_node.py
‚îÇ        ‚îú‚îÄ execution_node.py
‚îÇ        ‚îú‚îÄ output_validator_node.py
‚îÇ        ‚îú‚îÄ history_reader_node.py
‚îÇ        ‚îî‚îÄ summary_node.py
‚îÇ
‚îú‚îÄ providers/
‚îÇ  ‚îú‚îÄ provider_gateway.py      # Fachada unificada
‚îÇ  ‚îú‚îÄ registries/
‚îÇ  ‚îÇ  ‚îú‚îÄ model_registry.py     # Cat√°logo de modelos
‚îÇ  ‚îÇ  ‚îî‚îÄ strategy_registry.py  # Estrategias de sampling
‚îÇ  ‚îú‚îÄ local/
‚îÇ  ‚îÇ  ‚îú‚îÄ local_model_wrapper.py
‚îÇ  ‚îÇ  ‚îî‚îÄ manager/
‚îÇ  ‚îÇ     ‚îú‚îÄ model_manager.py
‚îÇ  ‚îÇ     ‚îî‚îÄ model_executor.py
‚îÇ  ‚îî‚îÄ remote/
‚îÇ     ‚îú‚îÄ openai_provider.py    # (pendiente)
‚îÇ     ‚îî‚îÄ anthropic_provider.py # (pendiente)
‚îÇ
‚îú‚îÄ utils/
‚îÇ  ‚îú‚îÄ logger.py
‚îÇ  ‚îú‚îÄ gpu_guard.py
‚îÇ  ‚îî‚îÄ analysis/
‚îÇ     ‚îî‚îÄ metrics_reader.py
‚îÇ
‚îú‚îÄ config.py                    # Configuraci√≥n central
‚îú‚îÄ .env                        # Variables de entorno
‚îî‚îÄ tests/
   ‚îú‚îÄ test_e2e_graph.py
   ‚îî‚îÄ test_provider_gateway.py
```

---

## 4) L√≠mites y responsabilidades

### 4.1 Orchestrator

* **Hace**: decide ruta, compone nodos, maneja reintentos/validaciones, agrega contexto (history, recursos), agrega m√©tricas.
* **No hace**: escoger proveedor espec√≠fico, ni hablar con HF/OpenAI/Anthropic, ni cargar modelos locales.
* **API esperada hacia Providers**: `ProviderGateway.generate(request: GenerationRequest) -> GenerationResult`.
* **Estado**: `AgentState` ahora incluye `version` y `request_id` para trazabilidad.

### 4.2 Provider Gateway

* **Responsabilidad**: traducir una solicitud abstracta en una invocaci√≥n concreta (local vs API) seg√∫n `model_key`, `strategy`, `task_type`, `constraints` (**VRAM**, **tokens**, **latencia**, **costo**).
* **Selecci√≥n**: usa `model_registry` (metadatos) + `strategy_registry` (pol√≠ticas de sampling/l√≠mites) + `gpu_guard` (capacidad actual).
* **Resultados**: normaliza salida (texto, tokens, timings, usage) + etiquetas (`cache_hit`, `source=local|openai|anthropic`).
* **Circuit Breaker b√°sico**: bloqueo temporal por proveedor tras N fallos consecutivos (`max_failures` configurable).

### 4.3 Local models manager

* Se conserva `ModelManager` + `ModelExecutor`, pero **exclusivamente detr√°s del Gateway**.
* Evitar que nodos llamen directamente a `local_models/*`.

---

## 5) Flujos

### 5.1 Direct Mode

`/api/inference` ‚Üí ProviderGateway.generate()

### 5.2 Orchestrated Execution - Linear Flow

`/api/orchestrate` ‚Üí `routing_agent.run(state, flow_type="linear")`

```
  ‚îú‚îÄ TaskAnalyzer ‚Üí set(task_type, requirements)
  ‚îú‚îÄ ResourceMonitor ‚Üí set(vram_status)
  ‚îú‚îÄ ExecutionNode ‚Üí ProviderGateway.generate()
  ‚îú‚îÄ OutputValidator ‚Üí retry/backoff si falla score
  ‚îú‚îÄ HistoryReader ‚Üí contexto relevante
  ‚îî‚îÄ SummaryNode ‚Üí final_summary + metrics
```

### 5.3 Challenge Flow - LLM Deliberation Workflows **NUEVO**

`/api/orchestrate` ‚Üí `routing_agent.run(state, flow_type="challenge")`

```
  ‚îú‚îÄ Creator ‚Üí genera soluci√≥n inicial
  ‚îú‚îÄ Challenger ‚Üí critica y encuentra problemas
  ‚îî‚îÄ Refiner ‚Üí mejora bas√°ndose en cr√≠ticas
```

**Casos de uso probados:**
- Validaci√≥n de contrase√±as con cr√≠tica autom√°tica
- Ping-pong efectivo entre modelos (3 ejecuciones secuenciales)
- Cache inteligente (51s carga inicial ‚Üí 19s ejecuciones subsecuentes)

### 5.4 Multi-perspective Flow **CONFIGURADO**

`/api/orchestrate` ‚Üí `routing_agent.run(state, flow_type="multi_perspective")`

```
         ‚îú‚îÄ Security Expert
  Input ‚îú‚îÄ Performance Expert ‚Üí Synthesizer ‚Üí Output
         ‚îî‚îÄ UX Expert
```

**Tipos de flow soportados:**
- `linear` - Pipeline tradicional
- `challenge` - Debate Creator‚ÜíChallenger‚ÜíRefiner  
- `multi_perspective` - Expertos paralelos + s√≠ntesis


## 6) Contratos

### 6.1 GenerationRequest

```python
class GenerationRequest(TypedDict):
    prompt: str
    model_key: str          # ej. "mistral7b"
    strategy: str           # ej. "optimized"
    max_tokens: int
    temperature: float
    task_type: str          # del Analyzer
    context: dict           # history, system, tools, etc.
    constraints: dict       # vram, latency_budget, cost_budget
```

### 6.2 GenerationResult

```python
class GenerationResult(TypedDict):
    text: str
    tokens_generated: int
    timings: dict           # load_time, inference_time, total
    usage: dict             # prompt_tokens, completion_tokens, cost (si aplica)
    source: str              # "local" | "openai" | "anthropic" | ...
    cache_hit: bool
    model_resolved: str     # id real (p.ej. hf repo o gpt-4o-mini)
```

---

## 7) Configuraci√≥n y registro

* `config.py`: lectura de `.env` (claves API, l√≠mites por entorno, flags de compatibilidad).
* `providers/registries/model_registry.py`:

  * **Campos**: `key`, `family`, `provider`, `context_window`, `default_strategy`, `capabilities` (tool-calling, function-schemas, vision), `cost_profile` (opc), `min_vram_gb`.
* `providers/registries/strategy_registry.py`:

  * **Campos**: `name`, `sampling` (temp, top\_p, top\_k), `limits` (max\_tokens, timeout), `fallbacks`.

---

## 8) Logging, m√©tricas, errores

* **Logging**: `utils/logger.py`, `utils/langgraph_logger.py` por nodo y por provider.
* **M√©tricas m√≠nimas**: tiempos, cache, source, reintentos, score de validador.
* **Errores**: clasificar por `ProviderError`, `ValidationError`, `CapacityError`; pol√≠tica de backoff exponencial en Orchestrator.
* **Circuit Breaker**: registrar bloqueos y recuperaciones por proveedor.

---

## 9) Testing

* **Smoke** por provider (local, openai, anthropic) con mocks cuando no hay claves.
* **E2E** del grafo: `tests/langgraph/test_end_to_end_graph.py` con fixtures de `AgentState`.
* **Determinismo**: seeds donde aplique; snapshot tests del Summary.
* **Circuit Breaker tests**: verificar bloqueo y recuperaci√≥n autom√°tica.

---

## 10) Plan de migraci√≥n desde V2

1. Crear `providers/` y mover **wrappers locales** all√≠.
2. Implementar `provider_gateway.py` con adapter para **local** (primero).
3. Cambiar `execution_node.py` para usar `ProviderGateway`.
4. Mover `routing_agent.py` + `agent_state.py` a `orchestrator/` (o crear alias temporal de import).
5. Sustituir `constants/models.py` ‚Üí `registries/model_registry.py`; `constants/strategies.py` ‚Üí `registries/strategy_registry.py`.
6. Mantener `Direct Mode` en `/inference` apuntando al Gateway.
7. Agregar adapter remoto m√≠nimo (OpenAI) detr√°s del Gateway.
8. Actualizar docs por archivo (secci√≥n 11).

---

## 11) Documentaci√≥n por archivo (RAG-ready)

### api/server.py

**Rol:** Entrypoint FastAPI, registra routers, DI de config, logging global.
**Funciones/Clases:**
* `create_app() -> FastAPI`
* Hooks startup/shutdown (warmup, cleanup)
**Entradas/Salidas:** HTTP; no l√≥gica de dominio.
**Depende de:** `config.py`, endpoints, logger.

### langchain_integration/langgraph/routing_agent.py

**Rol:** Orquestador principal SIMPLIFICADO - solo ejecuta grafos, no construye responses.
**Funciones principales:**
* `run_routing_agent(user_input, gateway, flow_type, verbose)` - Ejecuta flujos
* `run_orchestrator(prompt, flow_type)` - Wrapper para API con flow+metrics
**L√≠neas de c√≥digo:** ~140 l√≠neas (reducido de 250+ l√≠neas)
**No hace:** construcci√≥n de flow para frontend, l√≥gica compleja de m√©tricas
**Depende de:** `orchestration/`, `agent_state.py`, `ProviderGateway`

### langchain_integration/langgraph/orchestration/graph_builder.py

**Rol:** Construcci√≥n modular de grafos LangGraph.
**Funciones principales:**
* `GraphBuilder.build_linear_flow_graph()` - Grafo tradicional
* `GraphBuilder.build_challenge_flow_graph()` - Flujo de debate LLM
* `GraphBuilder.build_graph_from_config(config)` - Constructor din√°mico
* `get_graph_builder()` - Singleton pattern
**Caracter√≠sticas:** Nodos configurables, templates din√°micos, terminal node detection
**Depende de:** `graph_configs.py`, nodos existentes, `AgentState`

{
register_node(name, node_func) - Permite registrar nodos custom din√°micamente
_create_configurable_execution_node() - Crea nodos de ejecuci√≥n con configuraci√≥n espec√≠fica
_find_terminal_nodes(config) - Detecta nodos sin edges salientes para conectar a END
build_routing_graph(flow_type) - Funci√≥n de conveniencia para compatibilidad legacy

Gesti√≥n del estado Challenge Flow:

Guarda outputs en estructura state["challenge_flow"][node_id]
Persiste resultados en JSON: outputs/challenge_flows/{execution_id}.json
Mantiene compatibilidad con {node_id}_output keys

Routing condicional:

route_after_analysis() - Decide si usar monitor basado en task_type
Integraci√≥n con route_after_validation() del validator node
Soporte para should_include_history() del history node
}

### langchain_integration/langgraph/orchestration/graph_configs.py

**Rol:** Configuraciones declarativas de flujos - sistema n8n-like.
**Estructuras principales:**
* `FlowConfig` - Definici√≥n completa de flujo
* `NodeConfig` - Configuraci√≥n de nodo individual
* `EdgeConfig` - Conexiones entre nodos
**Funciones:**
* `get_challenge_flow_config()` - Config del flujo de debate
* `get_multi_perspective_flow_config()` - Config paralelo + s√≠ntesis
* `format_prompt_template()` - Templates con contexto din√°mico
**Escalabilidad:** Preparado para JSON configs y base de datos

**Flujos soportados:**
- `linear` - Flujo tradicional secuencial
- `challenge` - Debate creator‚Üíchallenger‚Üírefiner
- `multi_perspective` - An√°lisis paralelo con s√≠ntesis (pr√≥ximamente)

**Persistencia:**
- Challenge flows se guardan en `outputs/challenge_flows/`
- Formato: `{execution_id}.json` con estructura completa

**Extensibilidad:**
- Nuevos flujos se agregan en `FLOW_CONFIGS`
- Nodos custom via `GraphBuilder.register_node()`
- Templates soportan cualquier variable del estado

### langchain_integration/langgraph/orchestration/flow_metrics.py

**Rol:** Construcci√≥n de m√©tricas y flow data para frontend.
**Funciones principales:**
* `build_api_response(full_state, flow_type)` - Response completa para API
* `build_challenge_flow_nodes()` - Nodos espec√≠ficos para challenge flow
* `build_execution_metrics()` - M√©tricas de performance
* `build_error_response()` - Manejo de errores
**Separaci√≥n:** Extra√≠do de routing_agent.py para modularidad
**Depende de:** Estado de ejecuci√≥n, configuraciones de flow

### langchain_integration/langgraph/orchestration/__init__.py

**Rol:** Exports p√∫blicos del m√≥dulo de orquestaci√≥n.
**Exports:**
* `GraphBuilder`, `get_graph_builder`, `build_routing_graph`
* `get_flow_config`, `list_available_flows`  
* `build_api_response`, `get_flow_summary`
**Prop√≥sito:** API limpia para importar funcionalidad de orquestaci√≥n

### providers/provider_gateway.py

**Rol:** Orquesta proveedores locales/remotos.
**Funciones:** `generate(req)`, `resolve_model(req)`, `select_strategy(req)`
**Depende de:** registries, local manager, adapters remotos
**Estado:** Funcional, injection opcional via `hasattr(execution_mod, 'set_gateway')`

### providers/registries/model_registry.py

**Rol:** Cat√°logo de modelos disponibles y sus caracter√≠sticas.
**Funciones:** `get_model(key)`, `list_models()`, `supports_task(model_key, task_type)`
**Depende de:** ninguno (es data declarativa).

### langchain_integration/langgraph/nodes/execution_node.py

**Rol:** Nodo que ejecuta generaci√≥n v√≠a Provider Gateway.
**Funciones:** `execution_node(state)` 
**Integraci√≥n:** Preparado para Gateway injection, fallback a modo directo
**Configurabilidad:** Soporta nodos configurables con templates din√°micos
**NO hace:** NO selecciona modelo, solo invoca al Gateway.
**Depende de:** `ProviderGateway`, `AgentState`.

### utils/gpu_guard.py

**Rol:** Monitor de recursos GPU (VRAM disponible).
**Funciones:** `get_available_vram()`, `can_load_model(size_gb)`
**Depende de:** `torch`, `pynvml`.

12) Roadmap V3
Fase 1 - Core ‚úÖ COMPLETADO

 Estructura de carpetas V3
 Sistema de orquestaci√≥n modular (orchestration/)
 Challenge Flow - LLM Deliberation Workflows funcionando
 Graph Builder con configuraciones declarativas
 Flow metrics separados de routing logic
 Linear flow refactorizado y simplificado
 Provider Gateway b√°sico con injection opcional

Fase 1.5 - Refinamiento üîß EN PROGRESO

 Template context fix - Arreglar creator_output missing en Refiner
 Gateway injection consistency - Implementar set_gateway en execution_node
 JSON flow configs - Migrar de Python configs a JSON declarativo
 Multi-perspective flow testing - Probar flujo paralelo + s√≠ntesis

Fase 2 - Escalabilidad PR√ìXIMO

 Frontend visual builder (n8n-like interface)
 Base de datos para flows din√°micos
 API endpoints para crear/editar flows
 Flow validation y testing framework

Fase 3 - Providers Remotos

 OpenAI adapter completo
 Anthropic adapter completo
 Tests de fallback autom√°tico entre providers
 Rate limiting unificado por provider

Fase 4 - Observabilidad Avanzada

 M√©tricas Prometheus para challenge flows
 Dashboard espec√≠fico para debate flows
 Tracing distribuido cross-model

Estado actual: Challenge Flow probado exitosamente con 3 LLMs en secuencia, debate real entre modelos funcionando, arquitectura modular estable.

## 13) Variables de entorno (consolidadas)

```env
# Servicio
APP_ENV=dev
LOG_LEVEL=INFO
PORT=8001

# Providers
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
DEFAULT_PROVIDER=local
DEFAULT_STRATEGY=optimized
MAX_TOKENS_DEFAULT=1024

# Local execution
MAX_VRAM_USAGE_GB=6.0
MODEL_CACHE_DIR=.cache/models

# Circuit Breaker
CIRCUIT_BREAKER_MAX_FAILURES=3
CIRCUIT_BREAKER_TIMEOUT=60
```

---

## 14) Decisiones de dise√±o

* **Gateway pattern** para aislar cambios de proveedor y facilitar AB-testing.
* **Registry declarativo** para evitar hardcode en varios archivos.
* **Orchestrator minimalista**: separar routing de ejecuci√≥n.
* **Compatibilidad progresiva**: `Direct Mode` sigue operativo durante la migraci√≥n.
* **Circuit Breaker pattern**: resiliencia ante fallos de proveedores externos.
* **Versionado de estado**: trazabilidad completa de requests a trav√©s del grafo.

---

## 15) Ap√©ndice: Estado legado y acciones

* `constants/models.py`, `constants/strategies.py` ‚Üí **DEPRECATE** en favor de registries.
* `local_models/*` y `langchain_integration/wrappers/*` ‚Üí mover a `providers/local/`.
* `examples/`, `reference/`, `fix_hanging_model(Deprecado).py` ‚Üí `archive/`.

## 16) Ejemplos de uso

### Orchestrated Mode
```bash
curl -X POST http://localhost:8001/api/orchestrate \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Explain quantum computing",
    "strategy": "optimized",
    "max_tokens": 500
  }'


  ## üí° **Sugerencias adicionales:**

1. **Agregar diagrama de arquitectura** (usando Mermaid):
```mermaid
graph TB
    Client[Cliente] --> API[FastAPI Server]
    API --> GW[Provider Gateway]
    API --> ORC[Orchestrator/LangGraph]
    ORC --> GW
    GW --> Local[Local Models]
    GW --> OAI[OpenAI API]
    GW --> ANT[Anthropic API]
    
    subgraph "Circuit Breaker"
        GW --> CB[Circuit Breaker]
        CB --> Fallback[Fallback Logic]
    end

## 17) LLM Deliberation Workflows **NUEVO**

### 17.1 Concepto

Sistema de **debate inteligente entre modelos** donde m√∫ltiples LLMs colaboran y se critican mutuamente para mejorar la calidad de las soluciones.

**Inspiraci√≥n:** Replicar el proceso humano de revisi√≥n por pares, pero automatizado entre modelos IA.

### 17.2 Challenge Flow - Implementado

**Flujo:** Creator ‚Üí Challenger ‚Üí Refiner

```python
# Ejemplo de ejecuci√≥n real:
Creator (Mistral): Genera funci√≥n de validaci√≥n de contrase√±as
‚Üì
Challenger (Mistral): "La funci√≥n no verifica repeticiones consecutivas..."
‚Üì  
Refiner (Mistral): Mejora funci√≥n bas√°ndose en cr√≠ticas
```

**Prompts templates utilizados:**
- **Creator**: `"Genera una soluci√≥n para: {user_input}"`
- **Challenger**: `"Analiza cr√≠ticamente esta soluci√≥n... ¬øHay problemas de seguridad?"`
- **Refiner**: `"Mejora la soluci√≥n bas√°ndote en las cr√≠ticas recibidas..."`

### 17.3 Casos de Uso Probados

**Validaci√≥n de contrase√±as (Ejecutado exitosamente):**
1. Creator propuso funci√≥n b√°sica con regex
2. Challenger identific√≥: repeticiones no validadas, hardcoded word lists
3. Refiner (pendiente contexto fix) mejorar√≠a implementaci√≥n

**M√©tricas de ejecuci√≥n:**
- Tiempo total: ~90 segundos (3 modelos secuenciales)
- Cache hit rate: 67% (modelo ya cargado)
- Cr√≠ticas espec√≠ficas y t√©cnicamente v√°lidas generadas

### 17.4 Patrones de Debate Configurables

**Multi-perspective Flow:**
```
Input ‚Üí [Security Expert, Performance Expert, UX Expert] ‚Üí Synthesizer
```

**Adversarial Flow (futuro):**
```
Proposal ‚Üí Red Team ‚Üí Blue Team ‚Üí Arbitrator
```

**Consensus Flow (futuro):**
```
Input ‚Üí [Model A, Model B, Model C] ‚Üí Voting Mechanism ‚Üí Best Answer
```

### 17.5 Issues T√©cnicos Identificados

1. **Context sharing**: `creator_output` no disponible para Refiner
2. **Template expansion**: Necesita `{previous_output}`, `{challenger_output}` 
3. **Model routing**: Un solo modelo (Mistral) para todos los roles

### 17.6 Ventajas Observadas

‚úÖ **Cr√≠ticas reales**: Challenger encontr√≥ problemas t√©cnicos v√°lidos
‚úÖ **Especificidad**: Sugerencias concretas de mejora  
‚úÖ **Escalabilidad**: F√°cil agregar nuevos tipos de debate
‚úÖ **Modularidad**: Nodos independientes y reutilizables

### 17.7 Pr√≥ximos Experimentos

- **Multi-model**: Usar diferentes modelos por rol (Claude, GPT, Mistral)
- **Especializaci√≥n**: Crear expertos por dominio (security, performance, UX)
- **Iteraci√≥n**: M√∫ltiples rondas de cr√≠tica/refinamiento
- **Evaluaci√≥n**: M√©tricas autom√°ticas de mejora de calidad