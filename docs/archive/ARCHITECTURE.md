# ARCHITECTURE.md - AI-Agent-Lab

Este documento proporciona una descripci√≥n exhaustiva de la arquitectura del laboratorio de agentes LLM (entorno MGP). El sistema est√° dise√±ado para orquestar m√∫ltiples modelos de lenguaje grandes utilizando herramientas como LangChain, LangGraph y modelos locales, con capacidades avanzadas de routing, validaci√≥n autom√°tica, estrategias de carga optimizadas, m√©tricas comparativas y herramientas de diagn√≥stico integral.

---

## üéØ Prop√≥sito y Objetivos

El AI-Agent-Lab es un entorno experimental para:
- Orquestaci√≥n inteligente de m√∫ltiples LLMs locales
- Experimentaci√≥n con estrategias de carga y optimizaci√≥n de memoria
- Implementaci√≥n de flujos multi-agente con routing condicional
- Comparaci√≥n sistem√°tica de rendimiento entre modelos
- Desarrollo de agentes especializados con herramientas personalizadas

---

## üèóÔ∏è Arquitectura General

### Componentes Principales

```
AI-Agent-Lab/
‚îú‚îÄ‚îÄ main.py                          # Punto de entrada principal
‚îú‚îÄ‚îÄ config.py                        # Configuraci√≥n centralizada
‚îú‚îÄ‚îÄ fix_hanging_model.py            # Utilidad de recuperaci√≥n de emergencia
‚îÇ
‚îú‚îÄ‚îÄ local_models/                    # Gesti√≥n de modelos locales
‚îÇ   ‚îú‚îÄ‚îÄ llm_launcher.py             # Lanzador modular de modelos
‚îÇ   ‚îî‚îÄ‚îÄ loading_strategies.py       # Estrategias de carga especializadas
‚îÇ
‚îú‚îÄ‚îÄ langchain_integration/          # Integraci√≥n con LangChain/LangGraph
‚îÇ   ‚îú‚îÄ‚îÄ langgraph/                  # Implementaci√≥n de grafos de agentes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routing_agent.py        # Agente principal con routing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm_graph.py           # Construcci√≥n de grafos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local_llm_node.py      # Bridge para modelos locales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py          # Validaci√≥n de outputs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ nodes/                 # Nodos especializados del grafo
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ memory/                     # Gesti√≥n de memoria y cach√©
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ local_llm_manager.py   # Manager centralizado de modelos
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ tools/                      # Herramientas para agentes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lab_tools.py           # Herramientas del laboratorio
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ history_tools.py       # Herramientas de historial
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ wrappers/                   # Wrappers de modelos
‚îÇ       ‚îú‚îÄ‚îÄ local_model_wrapper.py  # Wrapper principal LangChain
‚îÇ       ‚îî‚îÄ‚îÄ hf_pipeline_wrappers/   # Wrappers espec√≠ficos de HuggingFace
‚îÇ
‚îú‚îÄ‚îÄ workers/                        # Procesos de trabajo
‚îÇ   ‚îî‚îÄ‚îÄ metrics_analyzer.py        # An√°lisis comparativo de m√©tricas
‚îÇ
‚îú‚îÄ‚îÄ utils/                          # Utilidades generales
‚îÇ   ‚îú‚îÄ‚îÄ gpu_guard.py               # Gesti√≥n y monitoreo de GPU
‚îÇ   ‚îú‚îÄ‚îÄ atomic_write.py            # Escritura at√≥mica de archivos
‚îÇ   ‚îú‚îÄ‚îÄ logger.py                  # Sistema de logging estructurado
‚îÇ   ‚îî‚îÄ‚îÄ logger_decorator.py        # Decoradores de logging
‚îÇ
‚îî‚îÄ‚îÄ tests/                          # Suite de pruebas
    ‚îú‚îÄ‚îÄ debugger_agent.py          # Agente AutoGen para debugging
    ‚îî‚îÄ‚îÄ langgraph/                 # Tests de componentes LangGraph
```

---

## üîÅ Modos de Ejecuci√≥n

### 1. **Modo Manual - CLI Interactiva**

**Archivo principal:** `main.py`

Caracter√≠sticas:
- Men√∫ interactivo para selecci√≥n de modelos y estrategias
- Ejecuci√≥n directa con par√°metros de l√≠nea de comandos
- Validaci√≥n autom√°tica de VRAM antes de cargar modelos
- Sistema de logging estructurado en JSON
- Limpieza autom√°tica de memoria GPU post-ejecuci√≥n

**Flujo de ejecuci√≥n:**
1. Inicializaci√≥n del entorno y validaci√≥n de configuraci√≥n
2. Detecci√≥n de modelos disponibles
3. Selecci√≥n interactiva o autom√°tica de modelo/estrategia
4. Carga del modelo seg√∫n estrategia seleccionada
5. Procesamiento del prompt
6. Almacenamiento de m√©tricas y outputs
7. Limpieza de recursos

### 2. **Modo Autom√°tico - Routing con LangGraph**

**Archivo principal:** `langchain_integration/langgraph/routing_agent.py`

Caracter√≠sticas:
- Flujo din√°mico basado en grafos de estado
- Routing condicional inteligente
- Recuperaci√≥n autom√°tica ante errores
- Validaci√≥n y reintentos autom√°ticos
- An√°lisis autom√°tico del tipo de tarea

**Arquitectura del Grafo:**

```mermaid
graph TD
    A[Inicio: routing_agent] --> B[task_analyzer_node]
    B --> C{Decisi√≥n de Routing}
    C -->|code/analysis| D[resource_monitor_node]
    C -->|chat| E[execution_node]
    D --> E
    E --> F[output_validator_node]
    F --> G{¬øV√°lido?}
    G -->|No - Retry| E
    G -->|S√≠| H[history_reader_node]
    H --> I{¬øIncluir historial?}
    I -->|read_history| J[summary_node]
    I -->|skip_history| J
    J --> K[END]
```

---

## üì¶ Componentes Detallados

### üîπ **main.py** - Punto de Entrada Principal

**Responsabilidades:**
- Parseo de argumentos CLI
- Inicializaci√≥n del entorno
- Coordinaci√≥n entre modo manual y autom√°tico
- Gesti√≥n del ciclo de vida de la aplicaci√≥n

**Funciones clave:**
- `main()`: Orquesta el flujo principal
- `parse_arguments()`: Procesa argumentos CLI
- `interactive_menu()`: Presenta men√∫ interactivo
- `execute_model()`: Coordina ejecuci√≥n con ModelLauncher

**Integraciones:**
- `config.py` para configuraci√≥n
- `local_models/llm_launcher.py` para ejecuci√≥n
- `utils/gpu_guard.py` para validaci√≥n de recursos

### üîπ **config.py** - Configuraci√≥n Centralizada

**Caracter√≠sticas:**
- Carga de variables desde `.env`
- Validaci√≥n autom√°tica de configuraci√≥n
- Valores por defecto seguros

**Variables gestionadas:**
```python
- OPENAI_API_KEY
- ANTHROPIC_API_KEY
- DEFAULT_MODEL
- DEFAULT_TEMPERATURE
- MAX_TOKENS
- LOG_LEVEL
```

**M√©todos principales:**
- `load_config()`: Carga configuraci√≥n desde entorno
- `validate()`: Valida integridad de configuraci√≥n
- `get_model_config()`: Retorna configuraci√≥n espec√≠fica por modelo

### üîπ **local_models/llm_launcher.py** - Lanzador Modular

**Arquitectura:**
```python
class ModelLauncher:
    def __init__(self, model_key: str, strategy: str)
    def launch(prompt: str, max_tokens: int, device_map: str) -> str
    def get_metrics() -> Dict[str, Any]
```

**Modelos soportados:**
```python
MODELS = {
    "llama3": "meta-llama/Meta-Llama-3-8B-Instruct",
    "mistral7b": "mistralai/Mistral-7B-Instruct-v0.2",
    "deepseek7b": "deepseek-ai/deepseek-llm-7b-chat",
    "deepseek-coder-6.7b": "deepseek-ai/deepseek-coder-6.7b-instruct"
}
```

**Caracter√≠sticas:**
- Logging estructurado por sesi√≥n
- M√©tricas detalladas de inferencia
- Persistencia autom√°tica de outputs
- Compatibilidad con `launch_model()` legacy

### üîπ **local_models/loading_strategies.py** - Estrategias de Carga

**Estrategias implementadas:**

1. **StandardLoadingStrategy**
   - Carga directa sin optimizaciones
   - M√°ximo rendimiento con alta demanda de VRAM
   - Ideal para GPUs con >16GB VRAM

2. **OptimizedLoadingStrategy**
   - Cuantizaci√≥n 4-bit con BitsAndBytes
   - Reduce uso de VRAM en ~75%
   - Balance entre rendimiento y recursos
   - Configuraci√≥n:
     ```python
     BitsAndBytesConfig(
         load_in_4bit=True,
         bnb_4bit_use_double_quant=True,
         bnb_4bit_quant_type="nf4",
         bnb_4bit_compute_dtype="bfloat16"
     )
     ```

3. **StreamingLoadingStrategy**
   - Generaci√≥n en tiempo real con TextStreamer
   - Feedback inmediato al usuario
   - Threading para generaci√≥n no bloqueante

**Placeholders para futuras estrategias:**
- `FastLoadingStrategy`: Carga acelerada con t√©cnicas avanzadas
- `CPULoadingStrategy`: Inferencia en CPU para sistemas sin GPU

### üîπ **langchain_integration/langgraph/routing_agent.py** - Orquestador Principal

**Estado del Grafo (AgentState):**
```python
class AgentState(TypedDict):
    input: str              # Prompt del usuario
    output: str             # Respuesta generada
    task_type: str          # Tipo de tarea detectada
    selected_model: str     # Modelo seleccionado
    strategy: str           # Estrategia de carga
    vram_status: str        # Estado de VRAM
    should_optimize: bool   # Flag de optimizaci√≥n
    messages: List[str]     # Log de mensajes del proceso
    analysis_result: str    # Resultado del an√°lisis
    final_summary: str      # Resumen final
    retry_count: int        # Contador de reintentos
    retry: bool            # Flag de reintento
    last_output: str       # √öltimo output del historial
```

**Funciones de routing condicional:**
- `route_after_analysis()`: Decide si monitorear recursos
- `route_after_validation()`: Decide si reintentar o continuar
- `should_include_history()`: Decide si leer historial

### üîπ **langchain_integration/langgraph/nodes/** - Nodos Especializados

#### **task_analyzer_node.py**
- Analiza el prompt para detectar tipo de tarea
- Categor√≠as: `code`, `technical`, `creative`, `analysis`, `chat`
- Utiliza `ModelSelectorTool` para recomendar modelo
- L√≥gica basada en palabras clave y contexto

#### **resource_monitor_node.py**
- Monitorea VRAM disponible v√≠a `VRAMMonitorTool`
- Decide estrategia √≥ptima seg√∫n recursos
- Umbrales configurables (default: 5GB para estrategia standard)
- Logging detallado de decisiones

#### **execution_node.py**
- Ejecuta el modelo seleccionado con la estrategia elegida
- Maneja errores y excepciones gracefully
- Integraci√≥n con `local_llm_node` para ejecuci√≥n
- M√©tricas de caracteres generados

#### **output_validator_node.py**
- Valida calidad del output generado
- Criterios de validaci√≥n:
  - Longitud m√≠nima (50 caracteres)
  - Ausencia de errores/excepciones
  - Coherencia b√°sica
- Sistema de reintentos con l√≠mite (`MAX_RETRIES = 1`)

#### **history_reader_node.py**
- Lee outputs anteriores desde `outputs/`
- Ordenamiento por fecha de modificaci√≥n
- Manejo robusto de errores de lectura
- Integraci√≥n opcional en el flujo

#### **summary_node.py**
- Genera resumen estructurado del proceso
- Incluye: tarea, modelo, estrategia, longitud, VRAM
- Formato compacto para logging

### üîπ **langchain_integration/memory/local_llm_manager.py** - Gesti√≥n de Memoria

**Caracter√≠sticas:**
- Cache centralizado de wrappers de modelos
- Reutilizaci√≥n eficiente de modelos cargados
- Gesti√≥n autom√°tica del ciclo de vida
- Limpieza expl√≠cita de recursos

**API principal:**
```python
class LocalLLMManager:
    def get_llm(model_key: str, strategy: str, **kwargs) -> LocalModelWrapper
    def clear_cache()
    def list_cached_models() -> list
```

### üîπ **langchain_integration/wrappers/local_model_wrapper.py** - Wrapper LangChain

**Caracter√≠sticas principales:**
- Hereda de `langchain_core.language_models.llms.LLM`
- Compatible con toda la infraestructura LangChain
- Soporta ambos modos: ModelLauncher y carga directa
- M√©tricas detalladas por sesi√≥n

**Campos configurables:**
```python
model_key: str          # Clave del modelo
strategy: str           # Estrategia de carga
max_tokens: int         # M√°ximo de tokens
temperature: float      # Temperatura de sampling
top_p: float           # Top-p sampling
device_map: str        # Mapeo de dispositivos
```

**M√©todos principales:**
- `_call()`: Generaci√≥n s√≠ncrona (requerido por LangChain)
- `_stream()`: Generaci√≥n en streaming
- `clear_model_cache()`: Limpieza de recursos
- `get_metrics()`: Obtenci√≥n de m√©tricas acumuladas

### üîπ **langchain_integration/tools/** - Herramientas para Agentes

#### **lab_tools.py**
1. **VRAMMonitorTool**
   - Monitorea memoria GPU en tiempo real
   - Retorna: VRAM libre, usada, total
   - Formato legible para humanos

2. **ModelSelectorTool**
   - Recomienda modelo seg√∫n contexto
   - An√°lisis de complejidad del prompt
   - Consideraci√≥n de recursos disponibles

3. **FileSearchTool**
   - B√∫squeda de archivos en el proyecto
   - Filtrado por extensi√≥n y contenido
   - √ötil para contexto adicional

#### **history_tools.py**
- **HistoryReaderNode**
  - Carga outputs hist√≥ricos
  - Parsing de metadatos
  - Integraci√≥n con el estado del grafo

### üîπ **utils/** - Utilidades del Sistema

#### **gpu_guard.py**
```python
def get_gpu_info() -> Dict[str, float]
def check_vram_availability(required_gb: float) -> bool
def clear_gpu_memory()
def get_compute_capability() -> float
```

#### **logger.py**
- Sistema de logging estructurado en JSON
- Logs por sesi√≥n y modelo
- Clase `LogAnalyzer` para an√°lisis post-hoc
- Rotaci√≥n autom√°tica de logs

#### **atomic_write.py**
- Escritura segura con archivos temporales
- Prevenci√≥n de corrupci√≥n de datos
- Soporte para JSON y texto plano

### üîπ **workers/metrics_analyzer.py** - An√°lisis Comparativo

**Funcionalidades:**
- Comparaci√≥n entre m√∫ltiples modelos
- M√©tricas de rendimiento (tiempo, tokens/seg)
- An√°lisis de similitud entre outputs
- Generaci√≥n de reportes CSV

**M√©tricas calculadas:**
- Tiempo promedio de inferencia
- Tokens por segundo
- Uso de memoria por modelo
- Similitud coseno entre outputs

### üîπ **fix_hanging_model.py** - Recuperaci√≥n de Emergencia

**M√≥dulos incluidos:**
1. **Monitor de Recursos**
   - CPU, RAM, GPU, Disco
   - Detecci√≥n de cuellos de botella

2. **Explorador de Cach√©**
   - An√°lisis de cach√© de HuggingFace
   - Limpieza selectiva

3. **Matador de Procesos**
   - Identificaci√≥n de procesos Python colgados
   - Terminaci√≥n segura

4. **Prueba de Generaci√≥n M√≠nima**
   - Test con configuraci√≥n minimal
   - Diagn√≥stico de problemas

5. **Recomendaciones Autom√°ticas**
   - An√°lisis de problemas detectados
   - Sugerencias de soluci√≥n

---

## üß™ Tests y Validaci√≥n

### Tests Unitarios (pytest)

**langgraph/**
- `test_end_to_end_graph.py`: Validaci√≥n de construcci√≥n del grafo
- `test_history_reader_node.py`: Comportamiento sin historial
- `test_output_validator_node.py`: Detecci√≥n de errores y retry
- `test_task_analyzer_node.py`: Clasificaci√≥n de tareas

### Test de Integraci√≥n

**debugger_agent.py**
- Agente AutoGen para debugging interactivo
- An√°lisis autom√°tico de errores Python
- Sugerencias de correcci√≥n

---

## üìä Flujos de Datos

### Flujo de Ejecuci√≥n Manual
```
Usuario ‚Üí main.py ‚Üí ModelLauncher ‚Üí LoadingStrategy ‚Üí HF Model ‚Üí Output
                 ‚Üì                                              ‚Üì
              Logging ‚Üê Metrics ‚Üê GPU Monitor ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üê ‚Üì
```

### Flujo de Ejecuci√≥n Autom√°tica (LangGraph)
```
Usuario ‚Üí routing_agent ‚Üí task_analyzer ‚Üí route_decision
                                              ‚Üì
                                     resource_monitor
                                              ‚Üì
                                      execution_node
                                              ‚Üì
                                    output_validator
                                         ‚Üì        ‚Üë
                                    [retry?] ‚Üê ‚Üê ‚Üê
                                         ‚Üì
                                   history_reader
                                         ‚Üì
                                    summary_node ‚Üí Output
```

---

## üîê Consideraciones de Seguridad y Rendimiento

### Gesti√≥n de Memoria
- Limpieza autom√°tica post-ejecuci√≥n
- Monitoreo continuo de VRAM
- Estrategias de carga adaptativas
- Cache inteligente de modelos

### Manejo de Errores
- Try-catch exhaustivos en puntos cr√≠ticos
- Logging detallado de excepciones
- Recuperaci√≥n autom√°tica cuando es posible
- Scripts de emergencia para casos extremos

### Optimizaciones
- Cuantizaci√≥n 4-bit para modelos grandes
- Streaming para feedback inmediato
- Reutilizaci√≥n de modelos cargados
- Escritura at√≥mica para prevenir corrupci√≥n

---

## üöÄ Gu√≠a de Uso R√°pido

### Ejecuci√≥n Manual B√°sica
```bash
# Men√∫ interactivo
python main.py

# Ejecuci√≥n directa
python main.py --model mistral7b --strategy optimized --prompt "Explica qu√© es Python"
```

### Ejecuci√≥n con LangGraph
```bash
# Pipeline autom√°tico completo
python langchain_integration/langgraph/routing_agent.py

# Con prompt espec√≠fico
python langchain_integration/langgraph/routing_agent.py --prompt "Escribe una funci√≥n fibonacci"
```

### Diagn√≥stico de Problemas
```bash
# Si un modelo se cuelga
python fix_hanging_model.py

# An√°lisis de m√©tricas
python workers/metrics_analyzer.py
```

---

## üîÑ Ciclo de Vida de una Solicitud

1. **Recepci√≥n**: El usuario env√≠a un prompt
2. **An√°lisis**: Se determina el tipo de tarea
3. **Selecci√≥n**: Se elige modelo y estrategia √≥ptimos
4. **Validaci√≥n**: Se verifican recursos disponibles
5. **Carga**: Se inicializa el modelo con la estrategia
6. **Generaci√≥n**: Se procesa el prompt
7. **Validaci√≥n**: Se verifica la calidad del output
8. **Persistencia**: Se guardan m√©tricas y resultados
9. **Limpieza**: Se liberan recursos
10. **Respuesta**: Se retorna el resultado al usuario

---

## üéØ Roadmap y Extensibilidad

### Implementado
- ‚úÖ Soporte multi-modelo local
- ‚úÖ Estrategias de carga optimizadas
- ‚úÖ Routing inteligente con LangGraph
- ‚úÖ Sistema de m√©tricas y logging
- ‚úÖ Validaci√≥n y reintentos autom√°ticos

### En Desarrollo
- üöß FastLoadingStrategy para carga acelerada
- üöß CPULoadingStrategy para sistemas sin GPU
- üöß Soporte para modelos en la nube
- üöß UI web para monitoreo en tiempo real

### Futuro
- üìã Orquestaci√≥n multi-GPU
- üìã Fine-tuning autom√°tico
- üìã Agentes especializados por dominio
- üìã Sistema de plugins extensible

---

## üìù Notas de Mantenimiento

- Mantener sincronizados los README.md de cada m√≥dulo
- Actualizar este documento con cada cambio arquitectural significativo
- Documentar decisiones de dise√±o en los PRs correspondientes
- Seguir convenciones de c√≥digo establecidas en `.editorconfig`

---

> *√öltima actualizaci√≥n: [Fecha actual]*
> *Versi√≥n: 2.0.0*
> *Mantenedor: AI-Agent-Lab Team*