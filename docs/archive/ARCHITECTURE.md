# ARCHITECTURE.md - AI-Agent-Lab

Este documento proporciona una descripciÃ³n exhaustiva de la arquitectura del laboratorio de agentes LLM (entorno MGP). El sistema estÃ¡ diseÃ±ado para orquestar mÃºltiples modelos de lenguaje grandes utilizando herramientas como LangChain, LangGraph y modelos locales, con capacidades avanzadas de routing, validaciÃ³n automÃ¡tica, estrategias de carga optimizadas, mÃ©tricas comparativas y herramientas de diagnÃ³stico integral.

---

## ðŸŽ¯ PropÃ³sito y Objetivos

El AI-Agent-Lab es un entorno experimental para:
- OrquestaciÃ³n inteligente de mÃºltiples LLMs locales
- ExperimentaciÃ³n con estrategias de carga y optimizaciÃ³n de memoria
- ImplementaciÃ³n de flujos multi-agente con routing condicional
- ComparaciÃ³n sistemÃ¡tica de rendimiento entre modelos
- Desarrollo de agentes especializados con herramientas personalizadas

---

## ðŸ—ï¸ Arquitectura General

### Componentes Principales

```
AI-Agent-Lab/
â”œâ”€â”€ main.py                          # Punto de entrada principal
â”œâ”€â”€ config.py                        # ConfiguraciÃ³n centralizada
â”œâ”€â”€ fix_hanging_model.py            # Utilidad de recuperaciÃ³n de emergencia
â”‚
â”œâ”€â”€ local_models/                    # GestiÃ³n de modelos locales
â”‚   â”œâ”€â”€ llm_launcher.py             # Lanzador modular de modelos
â”‚   â””â”€â”€ loading_strategies.py       # Estrategias de carga especializadas
â”‚
â”œâ”€â”€ langchain_integration/          # IntegraciÃ³n con LangChain/LangGraph
â”‚   â”œâ”€â”€ langgraph/                  # ImplementaciÃ³n de grafos de agentes
â”‚   â”‚   â”œâ”€â”€ routing_agent.py        # Agente principal con routing
â”‚   â”‚   â”œâ”€â”€ llm_graph.py           # ConstrucciÃ³n de grafos
â”‚   â”‚   â”œâ”€â”€ local_llm_node.py      # Bridge para modelos locales
â”‚   â”‚   â”œâ”€â”€ validators.py          # ValidaciÃ³n de outputs
â”‚   â”‚   â””â”€â”€ nodes/                 # Nodos especializados del grafo
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/                     # GestiÃ³n de memoria y cachÃ©
â”‚   â”‚   â””â”€â”€ local_llm_manager.py   # Manager centralizado de modelos
â”‚   â”‚
â”‚   â”œâ”€â”€ tools/                      # Herramientas para agentes
â”‚   â”‚   â”œâ”€â”€ lab_tools.py           # Herramientas del laboratorio
â”‚   â”‚   â””â”€â”€ history_tools.py       # Herramientas de historial
â”‚   â”‚
â”‚   â””â”€â”€ wrappers/                   # Wrappers de modelos
â”‚       â”œâ”€â”€ local_model_wrapper.py  # Wrapper principal LangChain
â”‚       â””â”€â”€ hf_pipeline_wrappers/   # Wrappers especÃ­ficos de HuggingFace
â”‚
â”œâ”€â”€ workers/                        # Procesos de trabajo
â”‚   â””â”€â”€ metrics_analyzer.py        # AnÃ¡lisis comparativo de mÃ©tricas
â”‚
â”œâ”€â”€ utils/                          # Utilidades generales
â”‚   â”œâ”€â”€ gpu_guard.py               # GestiÃ³n y monitoreo de GPU
â”‚   â”œâ”€â”€ atomic_write.py            # Escritura atÃ³mica de archivos
â”‚   â”œâ”€â”€ logger.py                  # Sistema de logging estructurado
â”‚   â””â”€â”€ logger_decorator.py        # Decoradores de logging
â”‚
â””â”€â”€ tests/                          # Suite de pruebas
    â”œâ”€â”€ debugger_agent.py          # Agente AutoGen para debugging
    â””â”€â”€ langgraph/                 # Tests de componentes LangGraph
```

---

## ðŸ” Modos de EjecuciÃ³n

### 1. **Modo Manual - CLI Interactiva**

**Archivo principal:** `main.py`

CaracterÃ­sticas:
- MenÃº interactivo para selecciÃ³n de modelos y estrategias
- EjecuciÃ³n directa con parÃ¡metros de lÃ­nea de comandos
- ValidaciÃ³n automÃ¡tica de VRAM antes de cargar modelos
- Sistema de logging estructurado en JSON
- Limpieza automÃ¡tica de memoria GPU post-ejecuciÃ³n

**Flujo de ejecuciÃ³n:**
1. InicializaciÃ³n del entorno y validaciÃ³n de configuraciÃ³n
2. DetecciÃ³n de modelos disponibles
3. SelecciÃ³n interactiva o automÃ¡tica de modelo/estrategia
4. Carga del modelo segÃºn estrategia seleccionada
5. Procesamiento del prompt
6. Almacenamiento de mÃ©tricas y outputs
7. Limpieza de recursos

### 2. **Modo AutomÃ¡tico - Routing con LangGraph**

**Archivo principal:** `langchain_integration/langgraph/routing_agent.py`

CaracterÃ­sticas:
- Flujo dinÃ¡mico basado en grafos de estado
- Routing condicional inteligente
- RecuperaciÃ³n automÃ¡tica ante errores
- ValidaciÃ³n y reintentos automÃ¡ticos
- AnÃ¡lisis automÃ¡tico del tipo de tarea

**Arquitectura del Grafo:**

```mermaid
graph TD
    A[Inicio: routing_agent] --> B[task_analyzer_node]
    B --> C{DecisiÃ³n de Routing}
    C -->|code/analysis| D[resource_monitor_node]
    C -->|chat| E[execution_node]
    D --> E
    E --> F[output_validator_node]
    F --> G{Â¿VÃ¡lido?}
    G -->|No - Retry| E
    G -->|SÃ­| H[history_reader_node]
    H --> I{Â¿Incluir historial?}
    I -->|read_history| J[summary_node]
    I -->|skip_history| J
    J --> K[END]
```

---

## ðŸ“¦ Componentes Detallados

### ðŸ”¹ **main.py** - Punto de Entrada Principal

**Responsabilidades:**
- Parseo de argumentos CLI
- InicializaciÃ³n del entorno
- CoordinaciÃ³n entre modo manual y automÃ¡tico
- GestiÃ³n del ciclo de vida de la aplicaciÃ³n

**Funciones clave:**
- `main()`: Orquesta el flujo principal
- `parse_arguments()`: Procesa argumentos CLI
- `interactive_menu()`: Presenta menÃº interactivo
- `execute_model()`: Coordina ejecuciÃ³n con ModelLauncher

**Integraciones:**
- `config.py` para configuraciÃ³n
- `local_models/llm_launcher.py` para ejecuciÃ³n
- `utils/gpu_guard.py` para validaciÃ³n de recursos

### ðŸ”¹ **config.py** - ConfiguraciÃ³n Centralizada

**CaracterÃ­sticas:**
- Carga de variables desde `.env`
- ValidaciÃ³n automÃ¡tica de configuraciÃ³n
- Valores por defecto seguros

**Variables gestionadas:**
```python
- OPENAI_API_KEY
- ANTHROPIC_API_KEY
- DEFAULT_MODEL
- DEFAULT_TEMPERATURE
- MAX_TOKENS
- LOG_LEVEL
```

**MÃ©todos principales:**
- `load_config()`: Carga configuraciÃ³n desde entorno
- `validate()`: Valida integridad de configuraciÃ³n
- `get_model_config()`: Retorna configuraciÃ³n especÃ­fica por modelo

### ðŸ”¹ **local_models/llm_launcher.py** - Lanzador Modular

**Arquitectura:**
```python
class ModelLauncher:
    def __init__(self, model_key: str, strategy: str)
    def launch(prompt: str, max_tokens: int, device_map: str) -> str
    def get_metrics() -> Dict[str, Any]
```

**Modelos soportados:**
```python
MODELS = {
    "llama3": "meta-llama/Meta-Llama-3-8B-Instruct",
    "mistral7b": "mistralai/Mistral-7B-Instruct-v0.2",
    "deepseek7b": "deepseek-ai/deepseek-llm-7b-chat",
    "deepseek-coder-6.7b": "deepseek-ai/deepseek-coder-6.7b-instruct"
}
```

**CaracterÃ­sticas:**
- Logging estructurado por sesiÃ³n
- MÃ©tricas detalladas de inferencia
- Persistencia automÃ¡tica de outputs
- Compatibilidad con `launch_model()` legacy

### ðŸ”¹ **local_models/loading_strategies.py** - Estrategias de Carga

**Estrategias implementadas:**

1. **StandardLoadingStrategy**
   - Carga directa sin optimizaciones
   - MÃ¡ximo rendimiento con alta demanda de VRAM
   - Ideal para GPUs con >16GB VRAM

2. **OptimizedLoadingStrategy**
   - CuantizaciÃ³n 4-bit con BitsAndBytes
   - Reduce uso de VRAM en ~75%
   - Balance entre rendimiento y recursos
   - ConfiguraciÃ³n:
     ```python
     BitsAndBytesConfig(
         load_in_4bit=True,
         bnb_4bit_use_double_quant=True,
         bnb_4bit_quant_type="nf4",
         bnb_4bit_compute_dtype="bfloat16"
     )
     ```

3. **StreamingLoadingStrategy**
   - GeneraciÃ³n en tiempo real con TextStreamer
   - Feedback inmediato al usuario
   - Threading para generaciÃ³n no bloqueante

**Placeholders para futuras estrategias:**
- `FastLoadingStrategy`: Carga acelerada con tÃ©cnicas avanzadas
- `CPULoadingStrategy`: Inferencia en CPU para sistemas sin GPU

### ðŸ”¹ **langchain_integration/langgraph/routing_agent.py** - Orquestador Principal

**Estado del Grafo (AgentState):**
```python
class AgentState(TypedDict):
    input: str              # Prompt del usuario
    output: str             # Respuesta generada
    task_type: str          # Tipo de tarea detectada
    selected_model: str     # Modelo seleccionado
    strategy: str           # Estrategia de carga
    vram_status: str        # Estado de VRAM
    should_optimize: bool   # Flag de optimizaciÃ³n
    messages: List[str]     # Log de mensajes del proceso
    analysis_result: str    # Resultado del anÃ¡lisis
    final_summary: str      # Resumen final
    retry_count: int        # Contador de reintentos
    retry: bool            # Flag de reintento
    last_output: str       # Ãšltimo output del historial
```

**Funciones de routing condicional:**
- `route_after_analysis()`: Decide si monitorear recursos
- `route_after_validation()`: Decide si reintentar o continuar
- `should_include_history()`: Decide si leer historial

### ðŸ”¹ **langchain_integration/langgraph/nodes/** - Nodos Especializados

#### **task_analyzer_node.py**
- Analiza el prompt para detectar tipo de tarea
- CategorÃ­as: `code`, `technical`, `creative`, `analysis`, `chat`
- Utiliza `ModelSelectorTool` para recomendar modelo
- LÃ³gica basada en palabras clave y contexto

#### **resource_monitor_node.py**
- Monitorea VRAM disponible vÃ­a `VRAMMonitorTool`
- Decide estrategia Ã³ptima segÃºn recursos
- Umbrales configurables (default: 5GB para estrategia standard)
- Logging detallado de decisiones

#### **execution_node.py**
- Ejecuta el modelo seleccionado con la estrategia elegida
- Maneja errores y excepciones gracefully
- IntegraciÃ³n con `local_llm_node` para ejecuciÃ³n
- MÃ©tricas de caracteres generados

#### **output_validator_node.py**
- Valida calidad del output generado
- Criterios de validaciÃ³n:
  - Longitud mÃ­nima (50 caracteres)
  - Ausencia de errores/excepciones
  - Coherencia bÃ¡sica
- Sistema de reintentos con lÃ­mite (`MAX_RETRIES = 1`)

#### **history_reader_node.py**
- Lee outputs anteriores desde `outputs/`
- Ordenamiento por fecha de modificaciÃ³n
- Manejo robusto de errores de lectura
- IntegraciÃ³n opcional en el flujo

#### **summary_node.py**
- Genera resumen estructurado del proceso
- Incluye: tarea, modelo, estrategia, longitud, VRAM
- Formato compacto para logging

### ðŸ”¹ **langchain_integration/memory/local_llm_manager.py** - GestiÃ³n de Memoria

**CaracterÃ­sticas:**
- Cache centralizado de wrappers de modelos
- ReutilizaciÃ³n eficiente de modelos cargados
- GestiÃ³n automÃ¡tica del ciclo de vida
- Limpieza explÃ­cita de recursos

**API principal:**
```python
class LocalLLMManager:
    def get_llm(model_key: str, strategy: str, **kwargs) -> LocalModelWrapper
    def clear_cache()
    def list_cached_models() -> list
```

### ðŸ”¹ **langchain_integration/wrappers/local_model_wrapper.py** - Wrapper LangChain

**CaracterÃ­sticas principales:**
- Hereda de `langchain_core.language_models.llms.LLM`
- Compatible con toda la infraestructura LangChain
- Soporta ambos modos: ModelLauncher y carga directa
- MÃ©tricas detalladas por sesiÃ³n

**Campos configurables:**
```python
model_key: str          # Clave del modelo
strategy: str           # Estrategia de carga
max_tokens: int         # MÃ¡ximo de tokens
temperature: float      # Temperatura de sampling
top_p: float           # Top-p sampling
device_map: str        # Mapeo de dispositivos
```

**MÃ©todos principales:**
- `_call()`: GeneraciÃ³n sÃ­ncrona (requerido por LangChain)
- `_stream()`: GeneraciÃ³n en streaming
- `clear_model_cache()`: Limpieza de recursos
- `get_metrics()`: ObtenciÃ³n de mÃ©tricas acumuladas

### ðŸ”¹ **langchain_integration/tools/** - Herramientas para Agentes

#### **lab_tools.py**
1. **VRAMMonitorTool**
   - Monitorea memoria GPU en tiempo real
   - Retorna: VRAM libre, usada, total
   - Formato legible para humanos

2. **ModelSelectorTool**
   - Recomienda modelo segÃºn contexto
   - AnÃ¡lisis de complejidad del prompt
   - ConsideraciÃ³n de recursos disponibles

3. **FileSearchTool**
   - BÃºsqueda de archivos en el proyecto
   - Filtrado por extensiÃ³n y contenido
   - Ãštil para contexto adicional

#### **history_tools.py**
- **HistoryReaderNode**
  - Carga outputs histÃ³ricos
  - Parsing de metadatos
  - IntegraciÃ³n con el estado del grafo

### ðŸ”¹ **utils/** - Utilidades del Sistema

#### **gpu_guard.py**
```python
def get_gpu_info() -> Dict[str, float]
def check_vram_availability(required_gb: float) -> bool
def clear_gpu_memory()
def get_compute_capability() -> float
```

#### **logger.py**
- Sistema de logging estructurado en JSON
- Logs por sesiÃ³n y modelo
- Clase `LogAnalyzer` para anÃ¡lisis post-hoc
- RotaciÃ³n automÃ¡tica de logs

#### **atomic_write.py**
- Escritura segura con archivos temporales
- PrevenciÃ³n de corrupciÃ³n de datos
- Soporte para JSON y texto plano

### ðŸ”¹ **workers/metrics_analyzer.py** - AnÃ¡lisis Comparativo

**Funcionalidades:**
- ComparaciÃ³n entre mÃºltiples modelos
- MÃ©tricas de rendimiento (tiempo, tokens/seg)
- AnÃ¡lisis de similitud entre outputs
- GeneraciÃ³n de reportes CSV

**MÃ©tricas calculadas:**
- Tiempo promedio de inferencia
- Tokens por segundo
- Uso de memoria por modelo
- Similitud coseno entre outputs

### ðŸ”¹ **fix_hanging_model.py** - RecuperaciÃ³n de Emergencia

**MÃ³dulos incluidos:**
1. **Monitor de Recursos**
   - CPU, RAM, GPU, Disco
   - DetecciÃ³n de cuellos de botella

2. **Explorador de CachÃ©**
   - AnÃ¡lisis de cachÃ© de HuggingFace
   - Limpieza selectiva

3. **Matador de Procesos**
   - IdentificaciÃ³n de procesos Python colgados
   - TerminaciÃ³n segura

4. **Prueba de GeneraciÃ³n MÃ­nima**
   - Test con configuraciÃ³n minimal
   - DiagnÃ³stico de problemas

5. **Recomendaciones AutomÃ¡ticas**
   - AnÃ¡lisis de problemas detectados
   - Sugerencias de soluciÃ³n

---

## ðŸ§ª Tests y ValidaciÃ³n

### Tests Unitarios (pytest)

**langgraph/**
- `test_end_to_end_graph.py`: ValidaciÃ³n de construcciÃ³n del grafo
- `test_history_reader_node.py`: Comportamiento sin historial
- `test_output_validator_node.py`: DetecciÃ³n de errores y retry
- `test_task_analyzer_node.py`: ClasificaciÃ³n de tareas

### Test de IntegraciÃ³n

**debugger_agent.py**
- Agente AutoGen para debugging interactivo
- AnÃ¡lisis automÃ¡tico de errores Python
- Sugerencias de correcciÃ³n

---

## ðŸ“Š Flujos de Datos

### Flujo de EjecuciÃ³n Manual
```
Usuario â†’ main.py â†’ ModelLauncher â†’ LoadingStrategy â†’ HF Model â†’ Output
                 â†“                                              â†“
              Logging â† Metrics â† GPU Monitor â† â† â† â† â† â† â† â† â†“
```

### Flujo de EjecuciÃ³n AutomÃ¡tica (LangGraph)
```
Usuario â†’ routing_agent â†’ task_analyzer â†’ route_decision
                                              â†“
                                     resource_monitor
                                              â†“
                                      execution_node
                                              â†“
                                    output_validator
                                         â†“        â†‘
                                    [retry?] â† â† â†
                                         â†“
                                   history_reader
                                         â†“
                                    summary_node â†’ Output
```

---

## ðŸ” Consideraciones de Seguridad y Rendimiento

### GestiÃ³n de Memoria
- Limpieza automÃ¡tica post-ejecuciÃ³n
- Monitoreo continuo de VRAM
- Estrategias de carga adaptativas
- Cache inteligente de modelos

### Manejo de Errores
- Try-catch exhaustivos en puntos crÃ­ticos
- Logging detallado de excepciones
- RecuperaciÃ³n automÃ¡tica cuando es posible
- Scripts de emergencia para casos extremos

### Optimizaciones
- CuantizaciÃ³n 4-bit para modelos grandes
- Streaming para feedback inmediato
- ReutilizaciÃ³n de modelos cargados
- Escritura atÃ³mica para prevenir corrupciÃ³n

---

## ðŸš€ GuÃ­a de Uso RÃ¡pido

### EjecuciÃ³n Manual BÃ¡sica
```bash
# MenÃº interactivo
python main.py

# EjecuciÃ³n directa
python main.py --model mistral7b --strategy optimized --prompt "Explica quÃ© es Python"
```

### EjecuciÃ³n con LangGraph
```bash
# Pipeline automÃ¡tico completo
python langchain_integration/langgraph/routing_agent.py

# Con prompt especÃ­fico
python langchain_integration/langgraph/routing_agent.py --prompt "Escribe una funciÃ³n fibonacci"
```

### DiagnÃ³stico de Problemas
```bash
# Si un modelo se cuelga
python fix_hanging_model.py

# AnÃ¡lisis de mÃ©tricas
python workers/metrics_analyzer.py
```

---

## ðŸ”„ Ciclo de Vida de una Solicitud

1. **RecepciÃ³n**: El usuario envÃ­a un prompt
2. **AnÃ¡lisis**: Se determina el tipo de tarea
3. **SelecciÃ³n**: Se elige modelo y estrategia Ã³ptimos
4. **ValidaciÃ³n**: Se verifican recursos disponibles
5. **Carga**: Se inicializa el modelo con la estrategia
6. **GeneraciÃ³n**: Se procesa el prompt
7. **ValidaciÃ³n**: Se verifica la calidad del output
8. **Persistencia**: Se guardan mÃ©tricas y resultados
9. **Limpieza**: Se liberan recursos
10. **Respuesta**: Se retorna el resultado al usuario

---

## ðŸŽ¯ Roadmap y Extensibilidad

### Implementado
- âœ… Soporte multi-modelo local
- âœ… Estrategias de carga optimizadas
- âœ… Routing inteligente con LangGraph
- âœ… Sistema de mÃ©tricas y logging
- âœ… ValidaciÃ³n y reintentos automÃ¡ticos

### En Desarrollo
- ðŸš§ FastLoadingStrategy para carga acelerada
- ðŸš§ CPULoadingStrategy para sistemas sin GPU
- ðŸš§ Soporte para modelos en la nube
- ðŸš§ UI web para monitoreo en tiempo real

### Futuro
- ðŸ“‹ OrquestaciÃ³n multi-GPU
- ðŸ“‹ Fine-tuning automÃ¡tico
- ðŸ“‹ Agentes especializados por dominio
- ðŸ“‹ Sistema de plugins extensible

---

## ðŸ“ Notas de Mantenimiento

- Mantener sincronizados los README.md de cada mÃ³dulo
- Actualizar este documento con cada cambio arquitectural significativo
- Documentar decisiones de diseÃ±o en los PRs correspondientes
- Seguir convenciones de cÃ³digo establecidas en `.editorconfig`

---

> *Ãšltima actualizaciÃ³n: [Fecha actual]*
> *VersiÃ³n: 2.0.0*
> *Mantenedor: AI-Agent-Lab Team*