# IA Agent Lab - LangGraph Integration

Este entorno est√° dise√±ado para ejecutar y orquestar m√∫ltiples modelos de lenguaje locales utilizando LangChain y LangGraph. La carpeta `langgraph_integration/` contiene una arquitectura modular y escalable basada en nodos y grafos de decisi√≥n. Esta gu√≠a documenta la estructura y prop√≥sito de cada archivo clave.

---

## üìä Estructura general

```
langchain_integration/
‚îú‚îÄ‚îÄ langgraph/
‚îÇ   ‚îú‚îÄ‚îÄ routing_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ validators.py
‚îÇ   ‚îú‚îÄ‚îÄ local_llm_node.py
‚îÇ   ‚îî‚îÄ‚îÄ llm_graph.py
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ lab_tools.py
‚îÇ   ‚îî‚îÄ‚îÄ history_tools.py
‚îî‚îÄ‚îÄ wrappers/
    ‚îî‚îÄ‚îÄ local_model_wrapper.py
```

---

## üîç langgraph/

### `routing_agent.py`

Agente principal de m√∫ltiples nodos con l√≥gica condicional y validaciones robustas.

* \`\`: Estado compartido entre nodos. Incluye `input`, `output`, `task_type`, `strategy`, `retry_count`, `last_output`, etc.
* **Nodos**:

  * `analyzer`: Determina el tipo de tarea y modelo.
  * `monitor`: Verifica recursos y decide estrategia (`standard` u `optimized`).
  * `executor`: Ejecuta el modelo local usando `local_llm_node`.
  * `validator`: Verifica si el output es v√°lido o requiere reintento.
  * `history`: Lee el √∫ltimo output previo del modelo desde disco.
  * `summarizer`: Genera resumen final del proceso.
* **Routing condicional**:

  * Despu√©s de `analyzer`: decide si salta el nodo `monitor`.
  * Despu√©s de `validator`: retry o continuar.
  * Despu√©s de `history`: decide si incluir historial.

### `validators.py`

* \`\`: Verifica la calidad del output generado. Aplica retry si es muy corto o contiene errores.
* \`\`: Devuelve `retry_execution` o `continue` seg√∫n el estado `retry`.
* `MAX_RETRIES` configurable.

### `local_llm_node.py`

* Contiene `build_local_llm_tool_node()`, una funci√≥n que genera un `ToolNode` configurado para ejecutar modelos locales usando wrappers.
* Internamente llama al `LocalModelWrapper`, que abstrae l√≥gica de carga, inferencia, logging y m√©tricas.

### `llm_graph.py`

* Versi√≥n simple y directa para probar un modelo local en un grafo lineal (`input -> model -> output`).
* Sirve como entorno m√≠nimo de prueba.

---

## üîß tools/

### `lab_tools.py`

Herramientas reutilizables como LangChain Tools o nodos:

* `VRAMMonitorTool`: Devuelve estado actual de la GPU.
* `ModelSelectorTool`: Devuelve un modelo sugerido seg√∫n input.
* `get_lab_tools()`: Devuelve todas las herramientas disponibles.

Estas herramientas son usadas tanto dentro de nodos como en evaluaci√≥n previa al grafo.

### `history_tools.py`

* `history_reader_node`: Nodo para leer el √∫ltimo output generado por el modelo usado (`outputs/modelo/runs/*.txt`).
* `should_include_history()`: Decide si se debe incluir historial (por ejemplo, para tareas `code` o `analysis`).
* Exporta `HistoryReaderNode` como `RunnableLambda`.

---

## üè† wrappers/

### `local_model_wrapper.py`

* Wrapper que abstrae la ejecuci√≥n del modelo.
* Maneja:

  * Carga desde HuggingFace con `transformers`.
  * Elecci√≥n de estrategia (`standard`, `optimized`, `streaming`).
  * Registro estructurado (m√©tricas, VRAM, logs por modelo).
* Incluye validaciones, logger personalizado y persistencia del output.

---

## üèÜ Recomendaciones de uso

* Ejecutar `routing_agent.py` para tener todo el sistema con routing activo.
* Usar `llm_graph.py` si se desea probar un solo modelo sin l√≥gica condicional.
* Todos los logs se guardan en `outputs/<modelo>/runs/`, con m√©tricas separadas por ejecuci√≥n.

---

## üåê Requisitos

* Python 3.12
* LangGraph >= 0.2.50
* Transformers, Accelerate, Pydantic, etc. (ver `requirements.txt`)
* GPU con al menos 8 GB VRAM (recomendado)

---

## üöÄ Roadmap futuro

*

---

Este entorno permite testear arquitecturas de agentes aut√≥nomos con decisiones din√°micas y evaluaci√≥n autom√°tica del output. Su dise√±o modular facilita la incorporaci√≥n de nuevos modelos, herramientas y estrategias.
