"""
Test del Challenge Flow - VersiÃ³n ARREGLADA
"""

from langchain_integration.langgraph.routing_agent import run_routing_agent, run_orchestrator

def test_challenge_flow_fixed():
    """Test del challenge flow con anÃ¡lisis mejorado."""
    
    print("ğŸ¥Š Testing Challenge Flow - VersiÃ³n Arreglada")
    print("=" * 60)
    
    # Prompt simple para test rÃ¡pido
    prompt = "Crea una funciÃ³n Python para validar emails"
    
    print(f"ğŸ“ Prompt: {prompt}")
    print(f"ğŸ”„ Flow: challenge (Creator â†’ Challenger â†’ Refiner)")
    print("\n" + "=" * 60)
    
    try:
        # Usar run_orchestrator para obtener flow data
        api_result = run_orchestrator(prompt, flow_type="challenge")
        
        print("\nğŸ¯ RESULTADO DEL CHALLENGE FLOW:")
        print("=" * 60)
        print(api_result.get('output', 'Sin output'))
        
        # Analizar el flow construido
        flow_data = api_result.get('flow', {})
        nodes = flow_data.get('nodes', [])
        edges = flow_data.get('edges', [])
        
        print("\nğŸ” ANÃLISIS DEL FLUJO (ARREGLADO):")
        print("=" * 60)
        
        # Verificar nodos por ID
        node_ids = [node['id'] for node in nodes]
        expected_nodes = ['creator', 'challenger', 'refiner']
        
        for expected_node in expected_nodes:
            if expected_node in node_ids:
                node_data = next(node for node in nodes if node['id'] == expected_node)
                print(f"âœ… {expected_node.capitalize()}: {node_data['status']}")
                print(f"   Output: {node_data['output'][:80]}...")
            else:
                print(f"âŒ {expected_node.capitalize()}: no encontrado")
        
        # AnÃ¡lisis de calidad basado en el output final
        output = api_result.get('output', '').lower()
        quality_indicators = {
            "validaciÃ³n": "valid" in output or "validar" in output,
            "email": "email" in output or "@" in output,
            "regex": "regex" in output or "re." in output,
            "funciÃ³n": "def " in output or "function" in output,
            "python": "python" in output or "def " in output
        }
        
        print(f"\nğŸ“Š ANÃLISIS DE CALIDAD:")
        print("=" * 60)
        for indicator, found in quality_indicators.items():
            status = "âœ…" if found else "âŒ"
            print(f"{status} {indicator.capitalize()}: {'Presente' if found else 'Ausente'}")
        
        quality_score = sum(quality_indicators.values()) / len(quality_indicators) * 100
        
        # MÃ©tricas
        metrics = api_result.get('metrics', {})
        total_time = metrics.get('totalTime', 0)
        workers = metrics.get('workersExecuted', 0)
        
        print(f"\nğŸ“ˆ MÃ‰TRICAS:")
        print("=" * 60)
        print(f"â±ï¸  Tiempo total: {total_time/1000:.1f}s")
        print(f"ğŸ‘¥ Workers ejecutados: {workers}")
        print(f"ğŸ“Š Score de calidad: {quality_score:.1f}%")
        print(f"ğŸ”„ Flow type: {metrics.get('flowType', 'unknown')}")
        
        # AnÃ¡lisis de ejecuciones secuenciales
        models_used = metrics.get('modelsUsed', [])
        print(f"ğŸ¤– Modelos utilizados: {', '.join(models_used)}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Error en challenge flow: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_challenge_flow_fixed()
    
    if success:
        print("\nğŸ‰ Challenge flow test arreglado completado!")
        print("ğŸ’¡ Ahora deberÃ­as ver correctamente los 3 nodos ejecutados")
    else:
        print("\nğŸ’¥ Challenge flow test aÃºn tiene problemas")